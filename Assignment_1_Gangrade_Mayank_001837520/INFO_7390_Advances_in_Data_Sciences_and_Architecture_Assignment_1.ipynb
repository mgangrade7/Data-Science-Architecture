{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Assignment 1\n",
    "\n",
    "**Due Friday, January 26 2018**\n",
    "\n",
    "_Submission: Put the data and Jupyter notebook files in a folder. Make sure all links to data are relative to the folder so the TAs can run the notebooks._\n",
    "\n",
    "Find a public dataset with a least 9 columns and 3000 rows. You must post your dataset on the class piazza and get an OK before using it as every student needs to use a _different_ dataset.\n",
    "\n",
    "## Individual Assignments\n",
    "\n",
    "These are individual assignments.  They cannot be done in groups.\n",
    "\n",
    "## Part A Cleaning and EDA (75 points)\n",
    "\n",
    "* Data cleaning\n",
    "    * Are there missing values?\n",
    "    * Are there inappropraite values?\n",
    "    * Remove or impute any bad data.\n",
    "\n",
    "* Answer the following questions for the data in each column:\n",
    "    * How is the data distributed?\n",
    "    * What are the summary statistics?\n",
    "    * Are there anomalies/outliers?\n",
    "\n",
    "* Plot each colmun as appropriate for the data type:\n",
    "    * Write a summary of what the plot tells you.\n",
    "    \n",
    "* Are any of the columns correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part B Writing a web scraper (25 points)\n",
    "\n",
    "Find a public website. You must post your website domain (e.g. amazon.com) on the class piazza and get an OK before using it as every student needs to use a _different_ website.\n",
    "\n",
    "* Website\n",
    "    * Collect all of the external links (there must be some on the page of your )\n",
    "    * Associate the link with a textual description of it from the website.\n",
    "    * Write a function to check whether the link is valid.\n",
    "    * Save the external links(urls), textual description, a boolean for valid, and the last vaild datetime check to an excel file.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## List of datasets for machine learning research\n",
    "\n",
    "* [List of datasets for machine learning research](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research)   \n",
    "* [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/)  \n",
    "* [Public Data Sets : Amazon Web Services](https://aws.amazon.com/datasets/) \n",
    "* [freebase](https://developers.google.com/freebase/)  \n",
    "* [Google Public Data Explorer](https://www.google.com/publicdata/directory)  \n",
    "* [datahub](http://datahub.io/)  \n",
    "* [data.gov](https://www.data.gov/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data cleaning checklist\n",
    "\n",
    " * Save original data\n",
    " * Identify missing data\n",
    " * Identify placeholder data (e.g. 0's for NA's) \n",
    " * Identify outliers\n",
    " * Check for overall plausibility and errors (e.g., typos, unreasonable ranges)\n",
    " * Identify highly correlated variables\n",
    " * Identify variables with (nearly) no variance\n",
    " * Identify variables with strange names or values\n",
    " * Check variable classes (eg. Characters vs factors)\n",
    " * Remove/transform some variables (maybe your model does not like categorial variables)\n",
    " * Rename some variables or values (if not all data is useful)\n",
    " * Check some overall pattern (statistical/ numerical summaries)\n",
    " * Possibly center/scale variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploratory Data Analysis checklist\n",
    "\n",
    "* Suggest hypotheses about the causes of observed phenomena\n",
    " * Assess assumptions on which statistical inference will be based\n",
    " * Support the selection of appropriate statistical tools and techniques\n",
    " * Provide a basis for further data collection through surveys or experiments\n",
    "\n",
    "_Five methods that are must have_:\n",
    "  \n",
    " * Five number summaries (mean/median, min, max, q1, q3)\n",
    " * Histograms \n",
    " * Line charts\n",
    " * Box and whisker plots\n",
    " * Pairwise scatterplots (scatterplot matrices)\n",
    " \n",
    " * What values do you see?\n",
    " * What distributions do you see?\n",
    " * What relationships do you see?\n",
    " * What relationships do you think might benefit the prediction problem?\n",
    "\n",
    "\n",
    "* Answer the following questions for the data in each column:\n",
    "    * How is the data distributed?\n",
    "    * Test distribution assumptions (e.G. Normal distributions or skewed?)\n",
    "    * What are the summary statistics?\n",
    "    * Are there anomalies/outliers?\n",
    "* Identify useful raw data & transforms (e.g. log(x))\n",
    "* Identify data quality problems\n",
    "* Identify outliers\n",
    "* Identify subsets of interest\n",
    "* Suggest functional relationships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last update September 5, 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
